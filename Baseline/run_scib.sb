#!/bin/bash --login
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=400G
#SBATCH --time=3:59:00
#SBATCH --job-name=scib
#SBATCH --account=cmse
#SBATCH --array=2-3
#SBATCH --output=./slurmout/%x-%j.SLURMout

## --gpus=v100:1
##  --gres=gpu:1
# conda activate  scInformer
conda activate  leiden
echo start: $(date +%H:%M:%S)

#TODO: to test if scib.me.cellcycle same as scib.metrics.metrics, and the speed
if [ $SLURM_ARRAY_TASK_ID  == 1 ]; then 
    srun python Eval_cellcycle.py --data HLCA_zstd_2000  --batch_correction batch 
fi 

##TODO: if no fast way, submit multiple jobs, per method per metric
## for loop, write one value in csv, use filename as index, value --> pd.DataFrame

#TODO: test for ari speed
if [ $SLURM_ARRAY_TASK_ID  == 2 ]; then 
    srun python Eval_scib.py --ari --data HLCA_zstd_2000  --batch_correction batch 
fi 

if [ $SLURM_ARRAY_TASK_ID  == 3 ]; then 
    srun python Eval_scib.py --CC --data HLCA_zstd_2000  --batch_correction batch 
fi 

# if [ $SLURM_ARRAY_TASK_ID  == 4 ]; then 
#     conda activate  saucie
#     srun python Saucie_integration.py --data HLCA_zstd_2000  --batch_correction batch 
# fi 

# if [ $SLURM_ARRAY_TASK_ID  == 5 ]; then 
#     srun python Eval_scib.py --data HLCA_zstd_2000  --batch_correction batch 
# fi 

echo end: $(date +%H:%M:%S)